{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/waveforms.pt\n",
      "/kaggle/input/train_meta.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'asr-shad'...\n",
      "remote: Enumerating objects: 1, done.\u001b[K\n",
      "remote: Counting objects: 100% (1/1), done.\u001b[K\n",
      "remote: Total 477 (delta 0), reused 0 (delta 0), pack-reused 476\u001b[K\n",
      "Receiving objects: 100% (477/477), 4.34 MiB | 9.64 MiB/s, done.\n",
      "Resolving deltas: 100% (284/284), done.\n",
      "\u001b[31mERROR: tpot 0.11.5 has requirement scikit-learn>=0.22.0, but you'll have scikit-learn 0.21.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: osmnx 0.15.1 has requirement geopandas>=0.7, but you'll have geopandas 0.6.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: osmnx 0.15.1 has requirement numpy>=1.18, but you'll have numpy 1.17.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: kornia 0.3.1 has requirement torch==1.5.0, but you'll have torch 1.5.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: kmeans-smote 0.1.2 has requirement imbalanced-learn<0.5,>=0.4.0, but you'll have imbalanced-learn 0.7.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: kmeans-smote 0.1.2 has requirement numpy<1.16,>=1.13, but you'll have numpy 1.17.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: kmeans-smote 0.1.2 has requirement scikit-learn<0.21,>=0.19.0, but you'll have scikit-learn 0.21.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: imbalanced-learn 0.7.0 has requirement scikit-learn>=0.23, but you'll have scikit-learn 0.21.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: dask-ml 1.5.0 has requirement numpy>=1.17.3, but you'll have numpy 1.17.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: dask-ml 1.5.0 has requirement scikit-learn>=0.23, but you'll have scikit-learn 0.21.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: cesium 0.9.12 has requirement scikit-learn>=0.22.1, but you'll have scikit-learn 0.21.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: bokeh 2.1.1 has requirement tornado>=5.1, but you'll have tornado 5.0.2 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/shonenkov/asr-shad > /dev/null\n",
    "!pip install -r './asr-shad/requirements.txt' > /dev/null\n",
    "import sys\n",
    "sys.path.insert(0, './asr-shad/utils')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# ASR Numbers\n",
    "## Наивные модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import torchaudio\n",
    "from sklearn.linear_model import SGDRegressor, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "\n",
    "from audio_stats import get_audio_stats\n",
    "from int_to_text import num2text\n",
    "from metrics import mean_wer, mean_ser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Описание гипотезы \n",
    "\n",
    "(объяснение постановки задачи машинного обучения с учителем: вход --> выход)\n",
    "\n",
    "Первое приближение. Будем решать задачу регрессии - предсказывать число по аудиозаписи. Применим для начала линейную регрессию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Реализация\n",
    "\n",
    "(код)\n",
    "\n",
    "Скачаем заранее подготовленные метаданные и статистику по датасету, оставим среди признаком только gender и frames, длительность и размер удалим, так как они хорошо скоррелированы с количеством фреймов. Добавим в train средние кепстральных коэффициентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# don't run\n",
    "\n",
    "train = pd.read_csv(INPUT_DIR + '/numbers/train.csv')\n",
    "train_stats = pd.read_csv(INPUT_DIR + '/train_audio_stats.csv')\n",
    "\n",
    "train['gender'] = train['gender'].apply(lambda x: 1 if x == 'female' else -1)\n",
    "train_stats['filename'] = train_stats['filename'].apply(lambda x: 'train/' + x)\n",
    "train_stats = train_stats[['filename', 'frames']]\n",
    "train = train.merge(train_stats, left_on='path', right_on='filename')\n",
    "train = train[['path', 'gender', 'frames', 'number']]\n",
    "\n",
    "def get_waveform(path):\n",
    "    waveform, _ = torchaudio.load(INPUT_DIR + '/numbers/' + path)\n",
    "    return waveform   \n",
    "\n",
    "waveforms = []\n",
    "for p in train['path']:\n",
    "    waveforms.append(get_waveform(p)) \n",
    "\n",
    "torch.save(waveforms, 'waveforms.pt')\n",
    "train.to_csv('train_meta.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# for the sake of performance download this data prepared in advance\n",
    "train = pd.read_csv('/kaggle/input/train_meta.csv')\n",
    "waves = torch.load('/kaggle/input/waveforms.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>gender</th>\n",
       "      <th>frames</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/e332b996d3.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>56923</td>\n",
       "      <td>157105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/e25afda49a.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>80659</td>\n",
       "      <td>374554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/364f147340.wav</td>\n",
       "      <td>-1</td>\n",
       "      <td>84807</td>\n",
       "      <td>688694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/5e0954b206.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>80601</td>\n",
       "      <td>265381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/7130a67690.wav</td>\n",
       "      <td>-1</td>\n",
       "      <td>72957</td>\n",
       "      <td>955415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   path  gender  frames  number\n",
       "0  train/e332b996d3.wav       1   56923  157105\n",
       "1  train/e25afda49a.wav       1   80659  374554\n",
       "2  train/364f147340.wav      -1   84807  688694\n",
       "3  train/5e0954b206.wav       1   80601  265381\n",
       "4  train/7130a67690.wav      -1   72957  955415"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check myself\n",
    "\n",
    "# train.shape\n",
    "# train.head()\n",
    "# len(waves)\n",
    "# type(waves), type(waves[0])\n",
    "# plt.plot(waves[0].t().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Средние для кепстральных коэффициентов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def wave_to_mfcc(waveform):\n",
    "    specgram = torchaudio.transforms.MFCC()(waveform)\n",
    "    mean_mfcc = torch.mean(specgram, 1)\n",
    "    return list(np.array(mean_mfcc.flatten()))\n",
    "\n",
    "mfcc_means = [wave_to_mfcc(waveform) for waveform in waves]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "mfcc_df = pd.DataFrame(mfcc_means)\n",
    "train_mfcc = pd.concat([train, mfcc_df], axis=1)\n",
    "train_mfcc.fillna(0, inplace=True)\n",
    "\n",
    "X = train_mfcc[['gender','frames'] + list(range(mfcc_df.shape[1]))]\n",
    "y = train['number']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Обучим линейный регрессор, посчитаем для предсказаний среднюю абсолютную ошибку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42.86985445022583\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "param_grid = [{'penalty': ['l2', 'l1', 'elasticnet'], \n",
    "               'alpha': [0.0001, 0.001, 0.01, 0.1], \n",
    "               'warm_start': [True, False]}]\n",
    "\n",
    "searcher = GridSearchCV(SGDRegressor(loss='squared_loss', random_state=42), \n",
    "                        param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "start = time.time()\n",
    "searcher.fit(X, y)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'alpha': 0.1, 'penalty': 'l2', 'warm_start': True}, -19492936160.51572)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searcher.best_params_, searcher.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Попробуем случайный лес. На части датасета случайный лес дает MAE порядка $2 \\cdot 10^5$ (у линейного регрессора выше $2\\cdot 10^{10}$), это значительное улучшение, также на малой подвыборке подбираем гиперпараметры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest fitting time =  160.35234713554382\n"
     ]
    }
   ],
   "source": [
    "param_grid = [{'criterion': ['mae', 'mse'], \n",
    "               'max_depth': [2, 3, 5, 10, 15, 20], \n",
    "               'n_estimators': [100, 200],\n",
    "              }]\n",
    "\n",
    "searcher = GridSearchCV(RandomForestRegressor(n_jobs=4, random_state=42), param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "\n",
    "start = time.time()\n",
    "searcher.fit(X[:100, :], y[:100])\n",
    "print('Random Forest fitting time = ', time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'criterion': 'mae', 'max_depth': 15, 'n_estimators': 100}, -207432.4473)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searcher.best_params_, searcher.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "На маленькой подвыборке подобраны гиперпараметры: criterion=mae, max_depth=15, n_estimators=100. \n",
    "Обучим случайный лес с этими параметрами на 3/4 элементах датасета, провалидируем на остальных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest fitting time = 2091.8834352493286\n"
     ]
    }
   ],
   "source": [
    "regressor = RandomForestRegressor(n_estimators=100, criterion='mae', max_depth=15, warm_start=True, n_jobs=4, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=True, random_state=42)\n",
    "\n",
    "start = time.time()\n",
    "regressor.fit(X_train, y_train)\n",
    "print('Random Forest fitting time =', time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22938.015215555555, 9946.760437777777)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = regressor.predict(X_test)\n",
    "score = mean_absolute_error(y_test, y_pred)\n",
    "score_fit = mean_absolute_error(y_train, regressor.predict(X_train))\n",
    "score, score_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Видим, что на всем датасете MAE уменьшилась еще в десять раз.\n",
    "Посмотрим, что этот результат значит для фраз и целевой метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7720624338624387, 0.5142236185981031)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = mean_wer([num2text(x) for x in y_test], [num2text(round(x, 0)) for x in y_pred])\n",
    "s = mean_ser([num2text(x) for x in y_test], [num2text(round(x, 0)) for x in y_pred])\n",
    "m, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>семьсот пятьдесят семь тысяч сто двадцать четыре</td>\n",
       "      <td>семьсот пятьдесят тысяч семьсот семьдесят восемь</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>пятьдесят девять тысяч двадцать два</td>\n",
       "      <td>восемьдесят тысяч шестьсот девяносто девять</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>семьсот сорок тысяч семьсот шестьдесят семь</td>\n",
       "      <td>шестьсот восемьдесят три тысячи девятьсот пять...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>сто шестьдесят четыре тысячи шестьсот шестьдес...</td>\n",
       "      <td>сто шестьдесят четыре тысячи семьсот девяносто...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>восемьсот сорок тысяч пятьсот пятьдесят три</td>\n",
       "      <td>восемьсот тридцать три тысячи восемьсот девять</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>пятьсот тридцать пять тысяч восемьсот восемьде...</td>\n",
       "      <td>пятьсот сорок шесть тысяч сто сорок пять</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>семьсот семьдесят девять тысяч пятьсот пятьдес...</td>\n",
       "      <td>семьсот шестьдесят тысяч семьсот пятьдесят шесть</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>четыреста пятьдесят пять тысяч восемьдесят один</td>\n",
       "      <td>четыреста пятьдесят одна тысяча четыреста пять...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>восемьсот пятьдесят шесть тысяч девятьсот трид...</td>\n",
       "      <td>семьсот восемьдесят одна тысяча девятьсот восемь</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>триста девяносто семь тысяч шестьсот десять</td>\n",
       "      <td>триста восемьдесят пять тысяч семьсот шесть</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>семьсот тридцать девять тысяч семьсот тридцать...</td>\n",
       "      <td>семьсот тридцать пять тысяч шестьсот тридцать два</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>пятьсот шестьдесят девять тысяч сто сорок два</td>\n",
       "      <td>пятьсот шестьдесят тысяч триста двадцать семь</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>двести сорок две тысячи восемьсот шестьдесят семь</td>\n",
       "      <td>двести сорок одна тысяча триста восемьдесят три</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>шестьсот двадцать пять тысяч шестьсот девять</td>\n",
       "      <td>шестьсот двадцать четыре тысячи триста семьдес...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>шестьсот сорок пять тысяч триста шесть</td>\n",
       "      <td>шестьсот тридцать две тысячи сто тридцать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>девятьсот тридцать пять тысяч сорок семь</td>\n",
       "      <td>девятьсот тридцать тысяч девятьсот тринадцать</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>сто четыре тысячи сто двадцать семь</td>\n",
       "      <td>сто пятьдесят семь тысяч десять</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>восемьсот восемьдесят шесть тысяч триста пятьд...</td>\n",
       "      <td>восемьсот восемьдесят тысяч четыреста восемнад...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>девять тысяч сто семьдесят четыре</td>\n",
       "      <td>пятьсот пятьдесят семь тысяч триста шестьдесят...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>двести пятьдесят две тысячи восемьсот двадцать...</td>\n",
       "      <td>двести пятьдесят три тысячи двести девяносто ш...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            reference  \\\n",
       "0    семьсот пятьдесят семь тысяч сто двадцать четыре   \n",
       "1                 пятьдесят девять тысяч двадцать два   \n",
       "2         семьсот сорок тысяч семьсот шестьдесят семь   \n",
       "3   сто шестьдесят четыре тысячи шестьсот шестьдес...   \n",
       "4         восемьсот сорок тысяч пятьсот пятьдесят три   \n",
       "5   пятьсот тридцать пять тысяч восемьсот восемьде...   \n",
       "6   семьсот семьдесят девять тысяч пятьсот пятьдес...   \n",
       "7     четыреста пятьдесят пять тысяч восемьдесят один   \n",
       "8   восемьсот пятьдесят шесть тысяч девятьсот трид...   \n",
       "9         триста девяносто семь тысяч шестьсот десять   \n",
       "10  семьсот тридцать девять тысяч семьсот тридцать...   \n",
       "11      пятьсот шестьдесят девять тысяч сто сорок два   \n",
       "12  двести сорок две тысячи восемьсот шестьдесят семь   \n",
       "13       шестьсот двадцать пять тысяч шестьсот девять   \n",
       "14             шестьсот сорок пять тысяч триста шесть   \n",
       "15           девятьсот тридцать пять тысяч сорок семь   \n",
       "16                сто четыре тысячи сто двадцать семь   \n",
       "17  восемьсот восемьдесят шесть тысяч триста пятьд...   \n",
       "18                  девять тысяч сто семьдесят четыре   \n",
       "19  двести пятьдесят две тысячи восемьсот двадцать...   \n",
       "\n",
       "                                           prediction  \n",
       "0    семьсот пятьдесят тысяч семьсот семьдесят восемь  \n",
       "1         восемьдесят тысяч шестьсот девяносто девять  \n",
       "2   шестьсот восемьдесят три тысячи девятьсот пять...  \n",
       "3   сто шестьдесят четыре тысячи семьсот девяносто...  \n",
       "4      восемьсот тридцать три тысячи восемьсот девять  \n",
       "5            пятьсот сорок шесть тысяч сто сорок пять  \n",
       "6    семьсот шестьдесят тысяч семьсот пятьдесят шесть  \n",
       "7   четыреста пятьдесят одна тысяча четыреста пять...  \n",
       "8    семьсот восемьдесят одна тысяча девятьсот восемь  \n",
       "9         триста восемьдесят пять тысяч семьсот шесть  \n",
       "10  семьсот тридцать пять тысяч шестьсот тридцать два  \n",
       "11      пятьсот шестьдесят тысяч триста двадцать семь  \n",
       "12    двести сорок одна тысяча триста восемьдесят три  \n",
       "13  шестьсот двадцать четыре тысячи триста семьдес...  \n",
       "14          шестьсот тридцать две тысячи сто тридцать  \n",
       "15      девятьсот тридцать тысяч девятьсот тринадцать  \n",
       "16                    сто пятьдесят семь тысяч десять  \n",
       "17  восемьсот восемьдесят тысяч четыреста восемнад...  \n",
       "18  пятьсот пятьдесят семь тысяч триста шестьдесят...  \n",
       "19  двести пятьдесят три тысячи двести девяносто ш...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases = pd.DataFrame({'reference': [num2text(x) for x in y_test],\n",
    "                        'prediction': [num2text(round(x, 0)) for x in y_pred],\n",
    "    \n",
    "})\n",
    "phrases.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Попробуем другую стратегию: определять каждое слово при помощи деревьев. Тогда появляется подзадача по классификации на 41 класс (всего в датасете 41 слово). Также нужно научиться разделять фичи из MFCC на слова. Будем делить на слова список ненулевых коэффициентов равномерно, в трейне можно легко определить количество слов по числу, в тесте обучим модель, которая будет определять количество слов. Здесь линейная модель, зависящая от пола и количества фреймов, кажется разумной эвристикой. Действительно,  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y_text = np.array([num2text(x) for x in y])\n",
    "y_length = np.array([len(x.split()) for x in y_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  \"Setting penalty='none' will ignore the C and l1_ratio \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length defining regressor fitting time = 31.573340892791748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "X = train[['gender','frames']]\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "param_grid = [{'penalty': ['l2', 'none'],\n",
    "               'multi_class': ['ovr', 'multinomial'],\n",
    "               'C': [0.01, 0.1, 10], \n",
    "               'warm_start': [True, False],\n",
    "              }]\n",
    "\n",
    "length_classifier = GridSearchCV(LogisticRegression(solver='saga', random_state=42), \n",
    "                                 param_grid, cv=5, scoring='neg_mean_absolute_error')\n",
    "\n",
    "length_classifier.fit(X, y_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'C': 0.01,\n",
       "  'multi_class': 'multinomial',\n",
       "  'penalty': 'none',\n",
       "  'warm_start': True},\n",
       " -0.314)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_classifier.best_params_, length_classifier.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Теперь напишем функции для обучения и предсказания на каждом шаге кроссвалидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "COL_PER_WORD = 61\n",
    "\n",
    "corpus = list(set(word for string in [num2text(x) for x in y] for word in string.split()))\n",
    "word_to_class = {corpus[i]: i for i in range(len(corpus))}\n",
    "class_to_word = {i: corpus[i] for i in range(len(corpus))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def fit_classifier(clf, indices, X, y):\n",
    "    train = []\n",
    "    target = []\n",
    "    for i in indices:\n",
    "        phrase = list(num2text(y[i]).split())\n",
    "        length = len(phrase)\n",
    "        for j in range(length):\n",
    "            cur_dict = {'gender': X.at[i, 'gender'], 'frames': X.at[i, 'frames']}\n",
    "            cur_dict.update({idx: X.at[i, idx + j * COL_PER_WORD] for idx in range(COL_PER_WORD)})\n",
    "            train.append(cur_dict)\n",
    "            target.append(word_to_class[phrase[j]])\n",
    "    \n",
    "    train = pd.DataFrame(train) \n",
    "    target = np.array(target)\n",
    "    train.fillna(0, inplace=True)\n",
    "    clf.fit(train, target)\n",
    "    return clf\n",
    "\n",
    "def predict_phrases(clf, length_clf, indices, X):\n",
    "    y_pred = []\n",
    "    for i in indices:\n",
    "        num_words = length_clf.predict(pd.DataFrame({'gender': [X.at[i, 'gender']], 'frames': [X.at[i, 'frames']]}))\n",
    "        prediction = ''\n",
    "        for j in range(int(num_words)):\n",
    "            cur_dict = {'gender': [X.at[i, 'gender']], 'frames': [X.at[i, 'frames']]}\n",
    "            cur_dict.update({idx: [X.at[i, idx + j * COL_PER_WORD]] for idx in range(COL_PER_WORD)})\n",
    "            cur_df = pd.DataFrame(cur_dict)\n",
    "            cur_pred = clf.predict(cur_df)[0]\n",
    "            prediction += (class_to_word[cur_pred])\n",
    "            prediction += ' '\n",
    "        y_pred.append(prediction[:-1])\n",
    "    return np.array(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Реализуем кросс-валидацию на 3 фолдах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest classifier fitting time = 638.8470225334167\n"
     ]
    }
   ],
   "source": [
    "X = train_mfcc[['gender','frames'] + list(range(mfcc_df.shape[1]))]\n",
    "y = train['number']\n",
    "\n",
    "y_crosswal_pred = []\n",
    "\n",
    "start = time.time()\n",
    "for i in range(3):\n",
    "    clf = RandomForestClassifier(random_state=42)\n",
    "#    clf = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=15, random_state=42)\n",
    "    clf = fit_classifier(clf, [x for x in range(9000) if x not in range(3000 * i, 3000 * i + 3000)], X, y)\n",
    "    y_pred = predict_phrases(clf, length_classifier, [x for x in range(3000 * i, 3000 * i + 3000)], X)\n",
    "    y_crosswal_pred += list(y_pred)\n",
    "print('Random forest classifier fitting time =', time.time() - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Параметры: n_estimators=100, criterion='gini', max_depth=15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6049206349206062, 0.447248377170323)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_wer(y_crosswal_pred, y_text), mean_ser(y_crosswal_pred, y_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "С дефолтными параметрами лучше:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.568507936507922, 0.39320905609289897)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_wer(y_crosswal_pred, y_text), mean_ser(y_crosswal_pred, y_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Предикт\n",
    "\n",
    "(получение финального csv с OOF предиктом, три столбика: reference, prediction, filename - все поля текстовые)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>reference</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/e332b996d3.wav</td>\n",
       "      <td>сто пятьдесят семь тысяч сто пять</td>\n",
       "      <td>сто пятьдесят три тридцать шесть шесть шесть</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/e25afda49a.wav</td>\n",
       "      <td>триста семьдесят четыре тысячи пятьсот пятьдес...</td>\n",
       "      <td>триста двести семьдесят тысячи пятьсот три восемь</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/364f147340.wav</td>\n",
       "      <td>шестьсот восемьдесят восемь тысяч шестьсот дев...</td>\n",
       "      <td>шестьсот восемьдесят восемь сорок тысяч четыре...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/5e0954b206.wav</td>\n",
       "      <td>двести шестьдесят пять тысяч триста восемьдеся...</td>\n",
       "      <td>двести шестьдесят пять шестьсот тысяча тысячи ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/7130a67690.wav</td>\n",
       "      <td>девятьсот пятьдесят пять тысяч четыреста пятна...</td>\n",
       "      <td>девятьсот пятьдесят пять тысяч четыреста шесть...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train/5e39a8735b.wav</td>\n",
       "      <td>четыре тысячи двести восемьдесят</td>\n",
       "      <td>четыреста семьдесят две тридцать семь два два</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train/14b99654c7.wav</td>\n",
       "      <td>пятьсот четырнадцать тысяч шестьсот семьдесят ...</td>\n",
       "      <td>пятьсот четырнадцать тысяч тысяч шесть четыре ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train/d004a14da0.wav</td>\n",
       "      <td>восемьсот тысяч триста пятьдесят два</td>\n",
       "      <td>восемьсот тысяч триста тысяч два семь семь</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>train/d0b0aa52e0.wav</td>\n",
       "      <td>девяносто четыре тысячи семьсот двадцать семь</td>\n",
       "      <td>восемьсот четыре девятьсот тысяч восемьдесят о...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>train/48a917e81b.wav</td>\n",
       "      <td>семьсот пятьдесят три тысячи восемьсот восемьд...</td>\n",
       "      <td>семьсот пятьдесят тридцать тысяч восемь пятьде...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>train/4a4ba7e7e5.wav</td>\n",
       "      <td>триста тридцать четыре тысячи шестьсот пятьдес...</td>\n",
       "      <td>триста тридцать тысячи тысяч пятьсот двадцать три</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>train/4f5035b164.wav</td>\n",
       "      <td>шестьсот семьдесят шесть тысяч пятьсот восемьд...</td>\n",
       "      <td>шестьсот семьдесят шесть тысяч восемьдесят дев...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>train/a32cb2ec9a.wav</td>\n",
       "      <td>семьсот девяносто шесть тысяч семьсот десять</td>\n",
       "      <td>семьсот девяносто шесть тысяча семьдесят шесть...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>train/101850de62.wav</td>\n",
       "      <td>триста восемьдесят пять тысяч восемь</td>\n",
       "      <td>триста восемьдесят пять тысяч шесть два два</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>train/708d190208.wav</td>\n",
       "      <td>пятьсот шестьдесят восемь тысяч сто шесть</td>\n",
       "      <td>пятьсот шестьдесят тысяч шесть двадцать три три</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>train/b90381298e.wav</td>\n",
       "      <td>двадцать пять тысяч пятьсот тридцать два</td>\n",
       "      <td>двадцать пять тысячи девять пятьдесят восемь в...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>train/769ca2032a.wav</td>\n",
       "      <td>восемьсот сорок тысяч один</td>\n",
       "      <td>восемьсот сорок тысяч два семь семь семь</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>train/c6e4692c5d.wav</td>\n",
       "      <td>семьсот двадцать шесть тысяч семьсот пятьдесят...</td>\n",
       "      <td>семьсот двадцать восемь тысячи семь двадцать ч...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>train/b4c275ce77.wav</td>\n",
       "      <td>девятьсот тридцать девять тысяч сто пять</td>\n",
       "      <td>девятьсот тридцать девять тысячи двадцать три три</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>train/305ec3f988.wav</td>\n",
       "      <td>шестьсот восемь тысяч сто семьдесят один</td>\n",
       "      <td>шестьсот восемь тысяч тысяч семь три семь</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    path                                          reference  \\\n",
       "0   train/e332b996d3.wav                  сто пятьдесят семь тысяч сто пять   \n",
       "1   train/e25afda49a.wav  триста семьдесят четыре тысячи пятьсот пятьдес...   \n",
       "2   train/364f147340.wav  шестьсот восемьдесят восемь тысяч шестьсот дев...   \n",
       "3   train/5e0954b206.wav  двести шестьдесят пять тысяч триста восемьдеся...   \n",
       "4   train/7130a67690.wav  девятьсот пятьдесят пять тысяч четыреста пятна...   \n",
       "5   train/5e39a8735b.wav                   четыре тысячи двести восемьдесят   \n",
       "6   train/14b99654c7.wav  пятьсот четырнадцать тысяч шестьсот семьдесят ...   \n",
       "7   train/d004a14da0.wav               восемьсот тысяч триста пятьдесят два   \n",
       "8   train/d0b0aa52e0.wav      девяносто четыре тысячи семьсот двадцать семь   \n",
       "9   train/48a917e81b.wav  семьсот пятьдесят три тысячи восемьсот восемьд...   \n",
       "10  train/4a4ba7e7e5.wav  триста тридцать четыре тысячи шестьсот пятьдес...   \n",
       "11  train/4f5035b164.wav  шестьсот семьдесят шесть тысяч пятьсот восемьд...   \n",
       "12  train/a32cb2ec9a.wav       семьсот девяносто шесть тысяч семьсот десять   \n",
       "13  train/101850de62.wav               триста восемьдесят пять тысяч восемь   \n",
       "14  train/708d190208.wav          пятьсот шестьдесят восемь тысяч сто шесть   \n",
       "15  train/b90381298e.wav           двадцать пять тысяч пятьсот тридцать два   \n",
       "16  train/769ca2032a.wav                         восемьсот сорок тысяч один   \n",
       "17  train/c6e4692c5d.wav  семьсот двадцать шесть тысяч семьсот пятьдесят...   \n",
       "18  train/b4c275ce77.wav           девятьсот тридцать девять тысяч сто пять   \n",
       "19  train/305ec3f988.wav           шестьсот восемь тысяч сто семьдесят один   \n",
       "\n",
       "                                           prediction  \n",
       "0        сто пятьдесят три тридцать шесть шесть шесть  \n",
       "1   триста двести семьдесят тысячи пятьсот три восемь  \n",
       "2   шестьсот восемьдесят восемь сорок тысяч четыре...  \n",
       "3   двести шестьдесят пять шестьсот тысяча тысячи ...  \n",
       "4   девятьсот пятьдесят пять тысяч четыреста шесть...  \n",
       "5       четыреста семьдесят две тридцать семь два два  \n",
       "6   пятьсот четырнадцать тысяч тысяч шесть четыре ...  \n",
       "7          восемьсот тысяч триста тысяч два семь семь  \n",
       "8   восемьсот четыре девятьсот тысяч восемьдесят о...  \n",
       "9   семьсот пятьдесят тридцать тысяч восемь пятьде...  \n",
       "10  триста тридцать тысячи тысяч пятьсот двадцать три  \n",
       "11  шестьсот семьдесят шесть тысяч восемьдесят дев...  \n",
       "12  семьсот девяносто шесть тысяча семьдесят шесть...  \n",
       "13        триста восемьдесят пять тысяч шесть два два  \n",
       "14    пятьсот шестьдесят тысяч шесть двадцать три три  \n",
       "15  двадцать пять тысячи девять пятьдесят восемь в...  \n",
       "16           восемьсот сорок тысяч два семь семь семь  \n",
       "17  семьсот двадцать восемь тысячи семь двадцать ч...  \n",
       "18  девятьсот тридцать девять тысячи двадцать три три  \n",
       "19          шестьсот восемь тысяч тысяч семь три семь  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans = pd.DataFrame({'path': train['path'],\n",
    "                    'reference': y_text,\n",
    "                    'prediction': y_crosswal_pred    \n",
    "})\n",
    "ans.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Оценка качества\n",
    "\n",
    "(подсчет целевых метрик word error rate и symbol (char) error rate)\n",
    "\n",
    "Качество на валидации: \n",
    "\n",
    "$WER=0.568507936507922,$ $SER=0.39320905609289897$.\n",
    "\n",
    "Также интересно посмотреть на ошибки на разных словах (судя по табличке выше, чем больше номер слова, тем сильнее ошибается модель)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "errors = [0] * 7\n",
    "for i in range(ans.shape[0]):\n",
    "    ref = list(ans.at[i, 'reference'].split())\n",
    "    pred = list(ans.at[i, 'prediction'].split())\n",
    "    for j in range(max(len(ref), len(pred))):\n",
    "        if j < min(len(ref), len(pred)):\n",
    "            errors[j] += (ref[j] != pred[j])\n",
    "        elif j >= len(ref) or j >= len(pred):\n",
    "            errors[j] += 1\n",
    "            \n",
    "plt.bar(list(range(7)), errors)\n",
    "plt.xlabel('номер слова')\n",
    "plt.ylabel('количество фраз с ошибкой')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Субъективная оценка\n",
    "\n",
    "(почему не сработало или сработало, дальнейшее развитие подхода)\n",
    "\n",
    "Деревья неплохо способны определять отдельные слова, но для работы с фразами нужен более тонкий препроцессинг для разделения фраз на слова. Равномерная разбивка - эвристика, которая хорошо могла бы сработать только на очень коротких фразах. Видно, что к третьему слову в 44% фраз алгоритм ошибается. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "В этом подходе направления, в котором требуются усовершенствования - более точное определение количества слов, определение длин слов во фразе.\n",
    "\n",
    "Еще одно направление, в котором можно сформулировать и проверить много гипотез: генерация фичей, а именно, какие преобразования аудиосигнала использовать для обучения модели."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
