{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/waveforms.pt\n/kaggle/input/train_meta.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!git clone https://github.com/shonenkov/asr-shad > /dev/null\n!pip install -r './asr-shad/requirements.txt' > /dev/null\nimport sys\nsys.path.insert(0, './asr-shad/utils')","execution_count":2,"outputs":[{"output_type":"stream","text":"Cloning into 'asr-shad'...\nremote: Enumerating objects: 20, done.\u001b[K\nremote: Counting objects: 100% (20/20), done.\u001b[K\nremote: Compressing objects: 100% (15/15), done.\u001b[K\nremote: Total 496 (delta 9), reused 12 (delta 5), pack-reused 476\u001b[K\nReceiving objects: 100% (496/496), 4.37 MiB | 28.30 MiB/s, done.\nResolving deltas: 100% (293/293), done.\n\u001b[31mERROR: tpot 0.11.5 has requirement scikit-learn>=0.22.0, but you'll have scikit-learn 0.21.3 which is incompatible.\u001b[0m\n\u001b[31mERROR: osmnx 0.15.1 has requirement geopandas>=0.7, but you'll have geopandas 0.6.3 which is incompatible.\u001b[0m\n\u001b[31mERROR: osmnx 0.15.1 has requirement numpy>=1.18, but you'll have numpy 1.17.2 which is incompatible.\u001b[0m\n\u001b[31mERROR: kornia 0.3.1 has requirement torch==1.5.0, but you'll have torch 1.5.1 which is incompatible.\u001b[0m\n\u001b[31mERROR: kmeans-smote 0.1.2 has requirement imbalanced-learn<0.5,>=0.4.0, but you'll have imbalanced-learn 0.7.0 which is incompatible.\u001b[0m\n\u001b[31mERROR: kmeans-smote 0.1.2 has requirement numpy<1.16,>=1.13, but you'll have numpy 1.17.2 which is incompatible.\u001b[0m\n\u001b[31mERROR: kmeans-smote 0.1.2 has requirement scikit-learn<0.21,>=0.19.0, but you'll have scikit-learn 0.21.3 which is incompatible.\u001b[0m\n\u001b[31mERROR: imbalanced-learn 0.7.0 has requirement scikit-learn>=0.23, but you'll have scikit-learn 0.21.3 which is incompatible.\u001b[0m\n\u001b[31mERROR: dask-ml 1.5.0 has requirement numpy>=1.17.3, but you'll have numpy 1.17.2 which is incompatible.\u001b[0m\n\u001b[31mERROR: dask-ml 1.5.0 has requirement scikit-learn>=0.23, but you'll have scikit-learn 0.21.3 which is incompatible.\u001b[0m\n\u001b[31mERROR: cesium 0.9.12 has requirement scikit-learn>=0.22.1, but you'll have scikit-learn 0.21.3 which is incompatible.\u001b[0m\n\u001b[31mERROR: bokeh 2.1.1 has requirement tornado>=5.1, but you'll have tornado 5.0.2 which is incompatible.\u001b[0m\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport time\nimport torch\nimport torchaudio\nfrom sklearn.linear_model import SGDRegressor, LogisticRegression\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn import metrics\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.preprocessing import StandardScaler, PolynomialFeatures\n\nfrom audio_stats import get_audio_stats\nfrom int_to_text import num2text\nfrom metrics import mean_wer, mean_ser, levenshtein_distance","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Описание гипотезы \n\n(объяснение постановки задачи машинного обучения с учителем: вход --> выход)"},{"metadata":{},"cell_type":"markdown","source":"Первое приближение. Будем решать задачу регрессии - предсказывать число по аудиозаписи. Применим для начала линейную регрессию."},{"metadata":{},"cell_type":"markdown","source":"# Реализация\n\n(код)"},{"metadata":{},"cell_type":"markdown","source":"Скачаем заранее подготовленные метаданные и статистику по датасету, оставим среди признаком только gender и frames, длительность и размер удалим, так как они хорошо скоррелированы с количеством фреймов. Добавим в train средние кепстральных коэффициентов."},{"metadata":{"trusted":true},"cell_type":"code","source":"# don't run\n\ntrain = pd.read_csv(INPUT_DIR + '/numbers/train.csv')\ntrain_stats = pd.read_csv(INPUT_DIR + '/train_audio_stats.csv')\n\ntrain['gender'] = train['gender'].apply(lambda x: 1 if x == 'female' else -1)\ntrain_stats['filename'] = train_stats['filename'].apply(lambda x: 'train/' + x)\ntrain_stats = train_stats[['filename', 'frames']]\ntrain = train.merge(train_stats, left_on='path', right_on='filename')\ntrain = train[['path', 'gender', 'frames', 'number']]\n\ndef get_waveform(path):\n    waveform, _ = torchaudio.load(INPUT_DIR + '/numbers/' + path)\n    return waveform   \n\nwaveforms = []\nfor p in train['path']:\n    waveforms.append(get_waveform(p)) \n\ntorch.save(waveforms, 'waveforms.pt')\ntrain.to_csv('train_meta.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for the sake of performance download these data prepared in advance\ntrain = pd.read_csv('/kaggle/input/train_meta.csv')\nwaves = torch.load('/kaggle/input/waveforms.pt')","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check myself\n\n# train.shape\n# train.head()\n# len(waves)\n# type(waves), type(waves[0])\n# plt.plot(waves[0].t().numpy())","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"                   path  gender  frames  number\n0  train/e332b996d3.wav       1   56923  157105\n1  train/e25afda49a.wav       1   80659  374554\n2  train/364f147340.wav      -1   84807  688694\n3  train/5e0954b206.wav       1   80601  265381\n4  train/7130a67690.wav      -1   72957  955415","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>gender</th>\n      <th>frames</th>\n      <th>number</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train/e332b996d3.wav</td>\n      <td>1</td>\n      <td>56923</td>\n      <td>157105</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train/e25afda49a.wav</td>\n      <td>1</td>\n      <td>80659</td>\n      <td>374554</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train/364f147340.wav</td>\n      <td>-1</td>\n      <td>84807</td>\n      <td>688694</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train/5e0954b206.wav</td>\n      <td>1</td>\n      <td>80601</td>\n      <td>265381</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train/7130a67690.wav</td>\n      <td>-1</td>\n      <td>72957</td>\n      <td>955415</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def wave_to_mfcc(waveform):\n    specgram = torchaudio.transforms.MFCC()(waveform)\n    mean_mfcc = torch.mean(specgram, 1)\n    return list(np.array(mean_mfcc.flatten()))\n\nmfcc_means = [wave_to_mfcc(waveform) for waveform in waves]","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mfcc_df = pd.DataFrame(mfcc_means)\ntrain_mfcc = pd.concat([train, mfcc_df], axis=1)\ntrain_mfcc.fillna(0, inplace=True)\n\nX = train_mfcc[['gender','frames'] + list(range(mfcc_df.shape[1]))]\ny = train['number']","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Обучим линейный регрессор, посчитаем для предсказаний среднюю абсолютную ошибку."},{"metadata":{"trusted":true},"cell_type":"code","source":"#no need to run, the fitting now is moved to each step of crossvalidation \nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\nparam_grid = [{'penalty': ['l2', 'l1', 'elasticnet'], \n               'alpha': [0.0001, 0.001, 0.01, 0.1], \n               'warm_start': [True, False]}]\n\nsearcher = GridSearchCV(SGDRegressor(loss='squared_loss', random_state=42), \n                        param_grid, cv=5, scoring='neg_mean_absolute_error')\nstart = time.time()\nsearcher.fit(X, y)\nprint(time.time() - start)","execution_count":12,"outputs":[{"output_type":"stream","text":"42.86985445022583\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"searcher.best_params_, searcher.best_score_","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"({'alpha': 0.1, 'penalty': 'l2', 'warm_start': True}, -19492936160.51572)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Попробуем случайный лес. На части датасета случайный лес дает MAE порядка $2 \\cdot 10^5$ (у линейного регрессора выше $2\\cdot 10^{10}$), это значительное улучшение, также на малой подвыборке подбираем гиперпараметры."},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = [{'criterion': ['mae', 'mse'], \n               'max_depth': [2, 3, 5, 10, 15, 20], \n               'n_estimators': [100, 200],\n              }]\n\nsearcher = GridSearchCV(RandomForestRegressor(n_jobs=4, random_state=42), param_grid, cv=5, scoring='neg_mean_absolute_error')\n\nstart = time.time()\nsearcher.fit(X[:100, :], y[:100])\nprint('Random Forest fitting time = ', time.time() - start)","execution_count":14,"outputs":[{"output_type":"stream","text":"Random Forest fitting time =  160.35234713554382\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"searcher.best_params_, searcher.best_score_","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"({'criterion': 'mae', 'max_depth': 15, 'n_estimators': 100}, -207432.4473)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"На маленькой подвыборке подобраны гиперпараметры: criterion=mae, max_depth=15, n_estimators=100. \nОбучим случайный лес с этими параметрами на 3/4 элементах датасета, провалидируем на остальных."},{"metadata":{"trusted":true},"cell_type":"code","source":"regressor = RandomForestRegressor(n_estimators=100, criterion='mae', max_depth=15, warm_start=True, n_jobs=4, random_state=42)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=True, random_state=42)\n\nstart = time.time()\nregressor.fit(X_train, y_train)\nprint('Random Forest fitting time =', time.time() - start)","execution_count":16,"outputs":[{"output_type":"stream","text":"Random Forest fitting time = 2091.8834352493286\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = regressor.predict(X_test)\nscore = mean_absolute_error(y_test, y_pred)\nscore_fit = mean_absolute_error(y_train, regressor.predict(X_train))\nscore, score_fit","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"(22938.015215555555, 9946.760437777777)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Видим, что на всем датасете MAE уменьшилась еще в десять раз.\nПосмотрим, что этот результат значит для фраз и целевой метрики"},{"metadata":{"trusted":true},"cell_type":"code","source":"m = mean_wer([num2text(x) for x in y_test], [num2text(round(x, 0)) for x in y_pred])\ns = mean_ser([num2text(x) for x in y_test], [num2text(round(x, 0)) for x in y_pred])\nm, s","execution_count":18,"outputs":[{"output_type":"execute_result","execution_count":18,"data":{"text/plain":"(0.7720624338624387, 0.5142236185981031)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"phrases = pd.DataFrame({'reference': [num2text(x) for x in y_test],\n                        'prediction': [num2text(round(x, 0)) for x in y_pred],\n    \n})\nphrases.head(20)","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"                                            reference  \\\n0    семьсот пятьдесят семь тысяч сто двадцать четыре   \n1                 пятьдесят девять тысяч двадцать два   \n2         семьсот сорок тысяч семьсот шестьдесят семь   \n3   сто шестьдесят четыре тысячи шестьсот шестьдес...   \n4         восемьсот сорок тысяч пятьсот пятьдесят три   \n5   пятьсот тридцать пять тысяч восемьсот восемьде...   \n6   семьсот семьдесят девять тысяч пятьсот пятьдес...   \n7     четыреста пятьдесят пять тысяч восемьдесят один   \n8   восемьсот пятьдесят шесть тысяч девятьсот трид...   \n9         триста девяносто семь тысяч шестьсот десять   \n10  семьсот тридцать девять тысяч семьсот тридцать...   \n11      пятьсот шестьдесят девять тысяч сто сорок два   \n12  двести сорок две тысячи восемьсот шестьдесят семь   \n13       шестьсот двадцать пять тысяч шестьсот девять   \n14             шестьсот сорок пять тысяч триста шесть   \n15           девятьсот тридцать пять тысяч сорок семь   \n16                сто четыре тысячи сто двадцать семь   \n17  восемьсот восемьдесят шесть тысяч триста пятьд...   \n18                  девять тысяч сто семьдесят четыре   \n19  двести пятьдесят две тысячи восемьсот двадцать...   \n\n                                           prediction  \n0    семьсот пятьдесят тысяч семьсот семьдесят восемь  \n1         восемьдесят тысяч шестьсот девяносто девять  \n2   шестьсот восемьдесят три тысячи девятьсот пять...  \n3   сто шестьдесят четыре тысячи семьсот девяносто...  \n4      восемьсот тридцать три тысячи восемьсот девять  \n5            пятьсот сорок шесть тысяч сто сорок пять  \n6    семьсот шестьдесят тысяч семьсот пятьдесят шесть  \n7   четыреста пятьдесят одна тысяча четыреста пять...  \n8    семьсот восемьдесят одна тысяча девятьсот восемь  \n9         триста восемьдесят пять тысяч семьсот шесть  \n10  семьсот тридцать пять тысяч шестьсот тридцать два  \n11      пятьсот шестьдесят тысяч триста двадцать семь  \n12    двести сорок одна тысяча триста восемьдесят три  \n13  шестьсот двадцать четыре тысячи триста семьдес...  \n14          шестьсот тридцать две тысячи сто тридцать  \n15      девятьсот тридцать тысяч девятьсот тринадцать  \n16                    сто пятьдесят семь тысяч десять  \n17  восемьсот восемьдесят тысяч четыреста восемнад...  \n18  пятьсот пятьдесят семь тысяч триста шестьдесят...  \n19  двести пятьдесят три тысячи двести девяносто ш...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>reference</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>семьсот пятьдесят семь тысяч сто двадцать четыре</td>\n      <td>семьсот пятьдесят тысяч семьсот семьдесят восемь</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>пятьдесят девять тысяч двадцать два</td>\n      <td>восемьдесят тысяч шестьсот девяносто девять</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>семьсот сорок тысяч семьсот шестьдесят семь</td>\n      <td>шестьсот восемьдесят три тысячи девятьсот пять...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>сто шестьдесят четыре тысячи шестьсот шестьдес...</td>\n      <td>сто шестьдесят четыре тысячи семьсот девяносто...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>восемьсот сорок тысяч пятьсот пятьдесят три</td>\n      <td>восемьсот тридцать три тысячи восемьсот девять</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>пятьсот тридцать пять тысяч восемьсот восемьде...</td>\n      <td>пятьсот сорок шесть тысяч сто сорок пять</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>семьсот семьдесят девять тысяч пятьсот пятьдес...</td>\n      <td>семьсот шестьдесят тысяч семьсот пятьдесят шесть</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>четыреста пятьдесят пять тысяч восемьдесят один</td>\n      <td>четыреста пятьдесят одна тысяча четыреста пять...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>восемьсот пятьдесят шесть тысяч девятьсот трид...</td>\n      <td>семьсот восемьдесят одна тысяча девятьсот восемь</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>триста девяносто семь тысяч шестьсот десять</td>\n      <td>триста восемьдесят пять тысяч семьсот шесть</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>семьсот тридцать девять тысяч семьсот тридцать...</td>\n      <td>семьсот тридцать пять тысяч шестьсот тридцать два</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>пятьсот шестьдесят девять тысяч сто сорок два</td>\n      <td>пятьсот шестьдесят тысяч триста двадцать семь</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>двести сорок две тысячи восемьсот шестьдесят семь</td>\n      <td>двести сорок одна тысяча триста восемьдесят три</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>шестьсот двадцать пять тысяч шестьсот девять</td>\n      <td>шестьсот двадцать четыре тысячи триста семьдес...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>шестьсот сорок пять тысяч триста шесть</td>\n      <td>шестьсот тридцать две тысячи сто тридцать</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>девятьсот тридцать пять тысяч сорок семь</td>\n      <td>девятьсот тридцать тысяч девятьсот тринадцать</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>сто четыре тысячи сто двадцать семь</td>\n      <td>сто пятьдесят семь тысяч десять</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>восемьсот восемьдесят шесть тысяч триста пятьд...</td>\n      <td>восемьсот восемьдесят тысяч четыреста восемнад...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>девять тысяч сто семьдесят четыре</td>\n      <td>пятьсот пятьдесят семь тысяч триста шестьдесят...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>двести пятьдесят две тысячи восемьсот двадцать...</td>\n      <td>двести пятьдесят три тысячи двести девяносто ш...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Попробуем другую стратегию: определять каждое слово при помощи деревьев. Тогда появляется подзадача по классификации на 41 класс (всего в датасете 41 слово). Также нужно научиться разделять фичи из MFCC на слова. Будем делить на слова список ненулевых коэффициентов равномерно, в трейне можно легко определить количество слов по числу, в тесте обучим модель, которая будет определять количество слов. Здесь линейная модель, зависящая от пола и количества фреймов, кажется разумной эвристикой. Действительно,  "},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_mfcc[['gender','frames'] + list(range(mfcc_df.shape[1]))]\ny = train['number']\n\ny_text = np.array([num2text(x) for x in y])\ny_length = np.array([len(x.split()) for x in y_text])","execution_count":20,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"X = train[['gender','frames']]\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\nparam_grid = [{'penalty': ['l2', 'none'],\n               'multi_class': ['ovr', 'multinomial'],\n               'C': [0.01, 0.1, 10], \n               'warm_start': [True, False],\n              }]\n\nlength_classifier = GridSearchCV(LogisticRegression(solver='saga', random_state=42), \n                                 param_grid, cv=5, scoring='neg_mean_absolute_error')\n\nlength_classifier.fit(X, y_length)","execution_count":24,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/model_selection/_split.py:657: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n  % (min_groups, self.n_splits)), Warning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n","name":"stderr"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n","name":"stderr"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n","name":"stderr"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n","name":"stderr"},{"output_type":"stream","text":"Length defining regressor fitting time = 31.573340892791748\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"length_classifier.best_params_, length_classifier.best_score_","execution_count":25,"outputs":[{"output_type":"execute_result","execution_count":25,"data":{"text/plain":"({'C': 0.01,\n  'multi_class': 'multinomial',\n  'penalty': 'none',\n  'warm_start': True},\n -0.314)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Теперь напишем функции для обучения и предсказания на каждом шаге кроссвалидации."},{"metadata":{"trusted":true},"cell_type":"code","source":"COL_PER_WORD = 61\n\ncorpus = list(set(word for string in [num2text(x) for x in y] for word in string.split()))\nword_to_class = {corpus[i]: i for i in range(len(corpus))}\nclass_to_word = {i: corpus[i] for i in range(len(corpus))}","execution_count":48,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fit_classifier(clf, length_clf, indices, X, y):\n    X_length = X[['gender','frames']]\n    scaler = StandardScaler()\n    X_length = scaler.fit_transform(X_length)\n    \n    y_text = np.array([num2text(x) for x in y])\n    y_length = np.array([len(x.split()) for x in y_text])\n\n    length_clf.fit(X_length, y_length)\n    \n    train = []\n    target = []\n    for i in indices:\n        phrase = list(num2text(y[i]).split())\n        length = len(phrase)\n        for j in range(length):\n            cur_dict = {'gender': X.at[i, 'gender'], 'frames': X.at[i, 'frames']}\n            cur_dict.update({idx: X.at[i, max(0, idx + j * COL_PER_WORD)]\n                             for idx in range(-20, COL_PER_WORD + 20)})\n            train.append(cur_dict)\n            target.append(word_to_class[phrase[j]])\n    \n    train = pd.DataFrame(train) \n    target = np.array(target)\n    train.fillna(0, inplace=True)\n    clf.fit(train, target)\n    return clf, length_clf\n\ndef predict_phrases(clf, length_clf, indices, X):\n    y_pred = []\n    for i in indices:\n        num_words = length_clf.predict(pd.DataFrame({'gender': [X.at[i, 'gender']], 'frames': [X.at[i, 'frames']]}))\n        prediction = ''\n        for j in range(int(num_words)):\n            cur_dict = {'gender': [X.at[i, 'gender']], 'frames': [X.at[i, 'frames']]}\n            cur_dict.update({idx: [X.at[i, max(0, idx + j * COL_PER_WORD)]]\n                             for idx in range(-20, COL_PER_WORD + 20)})\n            cur_df = pd.DataFrame(cur_dict)\n            cur_pred = clf.predict(cur_df)[0]\n            prediction += (class_to_word[cur_pred])\n            prediction += ' '\n        y_pred.append(prediction[:-1])\n    return np.array(y_pred)","execution_count":73,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Реализуем кросс-валидацию на 3 фолдах."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_mfcc[['gender','frames'] + list(range(mfcc_df.shape[1]))]\ny = train['number']\n\ny_crosswal_pred = []\ntotal_time = 0\n\nstart = time.time()\nfor i in range(3):\n    clf = RandomForestClassifier(random_state=42)\n    length_clf = LogisticRegression(C=0.1, multi_class='multinomial', penalty='none', \n                                           warm_start=True, solver='saga', random_state=42)\n#    clf = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=15, random_state=42)\n    clf, length_clf = fit_classifier(clf, length_clf, \n                                     [x for x in range(9000) if x not in range(3000 * i, 3000 * i + 3000)], X, y)\n    \n    start_pred = time.time()\n    y_pred = predict_phrases(clf, length_clf, [x for x in range(3000 * i, 3000 * i + 3000)], X)\n    end_pred = time.time()\n    total_time += (end_pred - start_pred)\n    \n    y_crosswal_pred += list(y_pred)\n    \nprint('Random forest classifier fitting time =', time.time() - start)\nprint('Prediction total time =', total_time)","execution_count":74,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:1510: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n  \"Setting penalty='none' will ignore the C and l1_ratio \"\n/opt/conda/lib/python3.7/site-packages/sklearn/linear_model/sag.py:337: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n  \"the coef_ did not converge\", ConvergenceWarning)\n/opt/conda/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n","name":"stderr"},{"output_type":"stream","text":"Random forest classifier fitting time = 1038.3572356700897\nPrediction total time = 870.8944575786591\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Random forest classifier prediction time = {}s per file'.format(round(total_time / 9000, 6)))","execution_count":71,"outputs":[{"output_type":"stream","text":"Random forest classifier prediction time = 0.09124s per file\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_wer(y_crosswal_pred, y_text), mean_ser(y_crosswal_pred, y_text)","execution_count":52,"outputs":[{"output_type":"execute_result","execution_count":52,"data":{"text/plain":"(0.5259523809523768, 0.361007572451029)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Нахлест слов $\\pm 10$ с каждой стороны (соответственно соседние слова пересекаются по 20 фичам)."},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_wer(y_crosswal_pred, y_text), mean_ser(y_crosswal_pred, y_text)","execution_count":47,"outputs":[{"output_type":"execute_result","execution_count":47,"data":{"text/plain":"(0.5471587301587223, 0.3777327652537049)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"При нарезке на слова без пересечений качество: "},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_wer(y_crosswal_pred, y_text), mean_ser(y_crosswal_pred, y_text)","execution_count":39,"outputs":[{"output_type":"execute_result","execution_count":39,"data":{"text/plain":"(0.568507936507922, 0.39320905609289897)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Предикт\n\n(получение финального csv с OOF предиктом, три столбика: reference, prediction, filename - все поля текстовые)"},{"metadata":{"trusted":true},"cell_type":"code","source":"ans = pd.DataFrame({'path': train['path'],\n                    'reference': y_text,\n                    'prediction': y_crosswal_pred    \n})\nans.head(20)","execution_count":53,"outputs":[{"output_type":"execute_result","execution_count":53,"data":{"text/plain":"                    path                                          reference  \\\n0   train/e332b996d3.wav                  сто пятьдесят семь тысяч сто пять   \n1   train/e25afda49a.wav  триста семьдесят четыре тысячи пятьсот пятьдес...   \n2   train/364f147340.wav  шестьсот восемьдесят восемь тысяч шестьсот дев...   \n3   train/5e0954b206.wav  двести шестьдесят пять тысяч триста восемьдеся...   \n4   train/7130a67690.wav  девятьсот пятьдесят пять тысяч четыреста пятна...   \n5   train/5e39a8735b.wav                   четыре тысячи двести восемьдесят   \n6   train/14b99654c7.wav  пятьсот четырнадцать тысяч шестьсот семьдесят ...   \n7   train/d004a14da0.wav               восемьсот тысяч триста пятьдесят два   \n8   train/d0b0aa52e0.wav      девяносто четыре тысячи семьсот двадцать семь   \n9   train/48a917e81b.wav  семьсот пятьдесят три тысячи восемьсот восемьд...   \n10  train/4a4ba7e7e5.wav  триста тридцать четыре тысячи шестьсот пятьдес...   \n11  train/4f5035b164.wav  шестьсот семьдесят шесть тысяч пятьсот восемьд...   \n12  train/a32cb2ec9a.wav       семьсот девяносто шесть тысяч семьсот десять   \n13  train/101850de62.wav               триста восемьдесят пять тысяч восемь   \n14  train/708d190208.wav          пятьсот шестьдесят восемь тысяч сто шесть   \n15  train/b90381298e.wav           двадцать пять тысяч пятьсот тридцать два   \n16  train/769ca2032a.wav                         восемьсот сорок тысяч один   \n17  train/c6e4692c5d.wav  семьсот двадцать шесть тысяч семьсот пятьдесят...   \n18  train/b4c275ce77.wav           девятьсот тридцать девять тысяч сто пять   \n19  train/305ec3f988.wav           шестьсот восемь тысяч сто семьдесят один   \n\n                                           prediction  \n0   сто пятьдесят семьдесят девяносто пять шесть ш...  \n1   триста шестьсот тысяч тридцать тысячи семьдеся...  \n2   шестьсот восемьдесят восемь тысяч тысячи тысяч...  \n3   двести шестьдесят пятьдесят тысяч тысяч девяно...  \n4     девятьсот пятьдесят пять тысяч тысячи шесть два  \n5     четыреста двадцать тысяч семьдесят один два два  \n6   пятьсот четырнадцать тысяч тысячи тысячи пятьд...  \n7     восемьсот тысяч триста семьсот два девять шесть  \n8   девяносто восемьдесят тысячи тысяч девяносто в...  \n9   семьсот пятьдесят три тысячи восемьсот восемьд...  \n10  триста тридцать четыре тысячи тысяч двадцать в...  \n11  шестьсот семьдесят шесть тысячи двести шестьде...  \n12  семьсот девяносто тысячи тысяч шестьдесят девя...  \n13     триста восемьдесят пять тысячи сорок два шесть  \n14  пятьсот шестьдесят восемь шестьдесят триста со...  \n15  двадцать пять тысяч тридцать пятьдесят четыре ...  \n16  восемьсот тысяч восемнадцать девяносто семь се...  \n17  семьсот двадцать шесть тысяч восемьсот восемьд...  \n18      девятьсот тридцать восемь тысячи пять три два  \n19      шестьсот восемь тысяч триста пятьсот три семь  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>reference</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>train/e332b996d3.wav</td>\n      <td>сто пятьдесят семь тысяч сто пять</td>\n      <td>сто пятьдесят семьдесят девяносто пять шесть ш...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>train/e25afda49a.wav</td>\n      <td>триста семьдесят четыре тысячи пятьсот пятьдес...</td>\n      <td>триста шестьсот тысяч тридцать тысячи семьдеся...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>train/364f147340.wav</td>\n      <td>шестьсот восемьдесят восемь тысяч шестьсот дев...</td>\n      <td>шестьсот восемьдесят восемь тысяч тысячи тысяч...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>train/5e0954b206.wav</td>\n      <td>двести шестьдесят пять тысяч триста восемьдеся...</td>\n      <td>двести шестьдесят пятьдесят тысяч тысяч девяно...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>train/7130a67690.wav</td>\n      <td>девятьсот пятьдесят пять тысяч четыреста пятна...</td>\n      <td>девятьсот пятьдесят пять тысяч тысячи шесть два</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>train/5e39a8735b.wav</td>\n      <td>четыре тысячи двести восемьдесят</td>\n      <td>четыреста двадцать тысяч семьдесят один два два</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>train/14b99654c7.wav</td>\n      <td>пятьсот четырнадцать тысяч шестьсот семьдесят ...</td>\n      <td>пятьсот четырнадцать тысяч тысячи тысячи пятьд...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>train/d004a14da0.wav</td>\n      <td>восемьсот тысяч триста пятьдесят два</td>\n      <td>восемьсот тысяч триста семьсот два девять шесть</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>train/d0b0aa52e0.wav</td>\n      <td>девяносто четыре тысячи семьсот двадцать семь</td>\n      <td>девяносто восемьдесят тысячи тысяч девяносто в...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>train/48a917e81b.wav</td>\n      <td>семьсот пятьдесят три тысячи восемьсот восемьд...</td>\n      <td>семьсот пятьдесят три тысячи восемьсот восемьд...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>train/4a4ba7e7e5.wav</td>\n      <td>триста тридцать четыре тысячи шестьсот пятьдес...</td>\n      <td>триста тридцать четыре тысячи тысяч двадцать в...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>train/4f5035b164.wav</td>\n      <td>шестьсот семьдесят шесть тысяч пятьсот восемьд...</td>\n      <td>шестьсот семьдесят шесть тысячи двести шестьде...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>train/a32cb2ec9a.wav</td>\n      <td>семьсот девяносто шесть тысяч семьсот десять</td>\n      <td>семьсот девяносто тысячи тысяч шестьдесят девя...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>train/101850de62.wav</td>\n      <td>триста восемьдесят пять тысяч восемь</td>\n      <td>триста восемьдесят пять тысячи сорок два шесть</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>train/708d190208.wav</td>\n      <td>пятьсот шестьдесят восемь тысяч сто шесть</td>\n      <td>пятьсот шестьдесят восемь шестьдесят триста со...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>train/b90381298e.wav</td>\n      <td>двадцать пять тысяч пятьсот тридцать два</td>\n      <td>двадцать пять тысяч тридцать пятьдесят четыре ...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>train/769ca2032a.wav</td>\n      <td>восемьсот сорок тысяч один</td>\n      <td>восемьсот тысяч восемнадцать девяносто семь се...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>train/c6e4692c5d.wav</td>\n      <td>семьсот двадцать шесть тысяч семьсот пятьдесят...</td>\n      <td>семьсот двадцать шесть тысяч восемьсот восемьд...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>train/b4c275ce77.wav</td>\n      <td>девятьсот тридцать девять тысяч сто пять</td>\n      <td>девятьсот тридцать восемь тысячи пять три два</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>train/305ec3f988.wav</td>\n      <td>шестьсот восемь тысяч сто семьдесят один</td>\n      <td>шестьсот восемь тысяч триста пятьсот три семь</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Оценка качества\n\n(подсчет целевых метрик word error rate и symbol (char) error rate)\n\nКачество на валидации: \n\n$WER=0.5259523809523768,$ $SER=0.361007572451029$.\n\nТакже интересно посмотреть на ошибки на разных словах (судя по табличке выше, чем больше номер слова, тем сильнее ошибается модель)."},{"metadata":{"trusted":true},"cell_type":"code","source":"errors = [0] * 7\nfor i in range(ans.shape[0]):\n    ref = list(ans.at[i, 'reference'].split())\n    pred = list(ans.at[i, 'prediction'].split())\n    for j in range(max(len(ref), len(pred))):\n        if j < min(len(ref), len(pred)):\n            errors[j] += (ref[j] != pred[j])\n        elif j >= len(ref) or j >= len(pred):\n            errors[j] += 1\n            \nplt.bar(list(range(7)), errors)\nplt.xlabel('номер слова')\nplt.ylabel('количество фраз с ошибкой')\nplt.show()","execution_count":54,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# зависимость WER от длины фразы\nwer_of_len = [0] * 8\nnum_words_of_len = [0] * 8\nser_of_len = [0] * 8\nfor i in range(ans.shape[0]):\n    ref = list(ans.at[i, 'reference'].split())\n    pred = list(ans.at[i, 'prediction'].split())\n    num_words_of_len[len(ref)] += 1\n    wer_of_len[len(ref)] += (levenshtein_distance(ref, pred) / len(ref))\n    ser_of_len[len(ref)] += (\n        levenshtein_distance(ans.at[i, 'reference'], ans.at[i, 'prediction']) / len(ans.at[i, 'reference'])\n    )\nfor i in range(len(wer_of_len)):\n    if num_words_of_len[i] != 0:\n        wer_of_len[i] = wer_of_len[i] / num_words_of_len[i]\n        ser_of_len[i] = ser_of_len[i] / num_words_of_len[i]\n            \nfig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(18, 3), dpi=100)\n\nax1.bar(list(range(1, 8)), num_words_of_len[1:8])\nax1.set_xlabel('количество слов во фразе')\nax1.set_title('Гистограмма количества слов во фразе')\nax2.bar(list(range(3, 8)), wer_of_len[3:8])\nax2.set_xlabel('количество слов во фразе')\nax2.set_title('Средний WER для длинных фраз')\nax3.bar(list(range(3, 8)), ser_of_len[3:8])\nax3.set_xlabel('количество слов во фразе')\nax3.set_title('Средний SER для длинных фраз')\nplt.show()","execution_count":64,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1800x300 with 3 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"# Субъективная оценка\n\n(почему не сработало или сработало, дальнейшее развитие подхода)\n\nДеревья неплохо способны определять отдельные слова, но для работы с фразами нужен более тонкий препроцессинг для разделения фраз на слова. Равномерная разбивка - эвристика, которая хорошо могла бы сработать только на очень коротких фразах. Видно, что к третьему слову в 44% фраз алгоритм ошибается. \n\nВ этом подходе направления, в котором требуются усовершенстовавания - более точное определение количества слов, определение длин слов во фразе.\n\nЕще одно направление, в котором можно сформулировать и проверить много гипотез: генерация фичей, а именно, какие преобразования аудиосигнала использовать для обучения модели."}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}